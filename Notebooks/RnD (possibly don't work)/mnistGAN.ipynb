{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# (x_train, y_train) = (x_train[:100], y_train[:100])\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,BatchNormalization,LeakyReLU,\\\n",
    "                                    Flatten,Dense,Reshape,Conv2DTranspose\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Downsample Using Strided Convolutions (e.g. don’t use pooling layers).\n",
    "2. Upsample Using Strided Convolutions (e.g. use the transpose convolutional layer).\n",
    "3. Use LeakyReLU (e.g. don’t use the standard ReLU).\n",
    "4. Use Batch Normalization (e.g. standardize layer outputs after the activation).\n",
    "5. Use Gaussian Weight Initialization (e.g. a mean of 0.0 and stdev of 0.02).\n",
    "6. Use Adam Stochastic Gradient Descent (e.g. learning rate of 0.0002 and beta1 of 0.5).\n",
    "7. Scale Images to the Range [-1,1] (e.g. use tanh in the output of the generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 3137      \n",
      "=================================================================\n",
      "Total params: 41,217\n",
      "Trainable params: 40,961\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the discriminator model\n",
    "discriminator = Sequential()\n",
    "# downsample to 14x14\n",
    "discriminator.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=(28,28,1)))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "# downsample to 7x7\n",
    "discriminator.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "# classify\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "=================================================================\n",
      "Total params: 404,225\n",
      "Trainable params: 397,697\n",
      "Non-trainable params: 6,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the generator model\n",
    "generator = Sequential()\n",
    "# foundation for 7x7 image\n",
    "n_nodes = 64 * 7 * 7\n",
    "generator.add(Dense(n_nodes, input_dim=100))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Reshape((7, 7, 64)))\n",
    "# upsample to 14x14\n",
    "generator.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "# upsample to 28x28\n",
    "generator.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Conv2D(1, (3,3), activation='tanh', padding='same'))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         404225    \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 41217     \n",
      "=================================================================\n",
      "Total params: 445,442\n",
      "Trainable params: 397,697\n",
      "Non-trainable params: 47,745\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make weights in the discriminator not trainable\n",
    "discriminator.trainable = False\n",
    "# connect them\n",
    "gan_model = Sequential()\n",
    "# add generator\n",
    "gan_model.add(generator)\n",
    "# add the discriminator\n",
    "gan_model.add(discriminator)\n",
    "# compile gan_model\n",
    "gan_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_real_samples(dataset, n_batch):\n",
    "    number_of_rows = dataset.shape[0]\n",
    "    random_indices = np.random.choice(number_of_rows, size=n_batch, replace=False)\n",
    "    random_rows = dataset[random_indices, :]\n",
    "    random_rows = np.expand_dims(random_rows,axis=3)\n",
    "    return random_rows, np.ones(n_batch)\n",
    "# n_batch = 1\n",
    "# select_real_samples(x_train, n_batch)[0].shape,select_real_samples(x_train, n_batch)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_batch):\n",
    "    # generate points in the latent space\n",
    "\tx_input = np.random.randn(latent_dim * n_batch)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_batch, latent_dim)\n",
    "\treturn x_input\n",
    "\n",
    "# generate_latent_points(latent_dim, n_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_batch):\n",
    "    x_input = generate_latent_points(latent_dim, n_batch)\n",
    "    x_fake = generator.predict(x_input)\n",
    "    y_fake = np.zeros(n_batch)\n",
    "    return x_fake, y_fake\n",
    "\n",
    "# generate_fake_samples(generator, latent_dim, n_batch)[0].shape,generate_fake_samples(generator, latent_dim, n_batch)[1].shape\n",
    "\n",
    "# x_fake, y_fake = generate_fake_samples(generator, latent_dim, 1)\n",
    "# x_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# gan training algorithm\n",
    "def train(generator,discriminator,gan_model,n_batch=16,latent_dim=100,n_epochs=10):\n",
    "    latent_dim = 100\n",
    "    for i in range(n_epochs):\n",
    "        # get randomly selected 'real' samples\n",
    "        X_real, y_real = select_real_samples(x_train, n_batch)\n",
    "        # generate 'fake' examples\n",
    "        X_fake, y_fake = generate_fake_samples(generator, latent_dim, n_batch)\n",
    "        # create training set for the discriminator\n",
    "        X, y = np.vstack((X_real, X_fake)), np.hstack((y_real, y_fake))\n",
    "        # update discriminator model weights\n",
    "        d_loss = discriminator.train_on_batch(X, y)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i)\n",
    "        \n",
    "# train(generator,discriminator,gan_model,n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def testWeightFreeze(discriminator,generator,gan_model):\n",
    "    # discriminator changes\n",
    "    disc_weight_before = discriminator.non_trainable_weights[0][0][0][0][0].numpy()\n",
    "    gen_weight_before = generator.trainable_weights[0][0][0].numpy()\n",
    "    train(generator,discriminator,gan_model)\n",
    "    disc_weight_after = discriminator.non_trainable_weights[0][0][0][0][0].numpy()\n",
    "    gen_weight_after = generator.trainable_weights[0][0][0].numpy()\n",
    "\n",
    "    (disc_weight_before, disc_weight_after), (gen_weight_before,gen_weight_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fecacab9cc0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANrUlEQVR4nO3dT6xcZ33G8eepa0AJINn5Vze4DUWJ1KhKTHV1QUpVpULFIRuHBQgvkJFQzYJIILFolC7IMqr4IxYI6dJYmIoGIUEaL6JeLAspYhNyEzmOU7dOiFxsbNmOvUiQBSTOr4t7jC72zJzJvOffzO/7ka5m7jkz5/3NuX58ZuY973kdEQKw+P6k7wIAdIOwA0kQdiAJwg4kQdiBJP60y8Zu3Lopbtu+ucsmB+H4kesmrr/jrksdVdK8RX5tJfraLydOvqnXLl72qHVFYbd9n6RvSdok6d8i4tFJj79t+2b9YnV7SZNzaeef75i4fnX1cEeVNG+RX1uJvvbL8s6TY9fN/Dbe9iZJ35b0CUl3Stpt+85ZtwegXSWf2ZclvRIRr0bE7yX9UNKuZsoC0LSSsN8qaeN7hlPVsj9ie6/tNdtr5y9cLmgOQImSsI/6EuCac28jYiUiliJi6aYbNhU0B6BESdhPSdr4bdsHJJ0uKwdAW0rC/qyk221/0Pa7JH1G0oFmygLQtJm73iLiLdsPSlrVetfbvoh4adJzjh+5rrZLYlarp8u6Mmq7Sgq233ZtQ227dNultbepz/0yyfG4MHZdUT97RDwl6amSbQDoBqfLAkkQdiAJwg4kQdiBJAg7kARhB5LodDx7qZJ+1zb7dNvsc5WG+7qnef6k9kue28TzS7Zd2nbJfplkeef4cfIc2YEkCDuQBGEHkiDsQBKEHUiCsANJzFXX2yRtd3/12YVUp83X3udra7tbsE1ttj1pn08a4sqRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeScMQ1k7i0Zunu98RQZ3Et6S9e5Esi99VfPE3b83x+QVvnbTwTh/R6XBw5ZTNHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IYq762Yfcr9pn23324w+5tklK/55D/Zst7zyptRd+O7KfvejiFbZPSHpD0mVJb0XEUsn2ALSniSvV/ENEvNbAdgC0iM/sQBKlYQ9JP7X9nO29ox5ge6/tNdtr5y9cLmwOwKxK38bfExGnbd8s6aDt/4mIpzc+ICJWJK1I61/QFbYHYEZFR/aIOF3dnpP0hKTlJooC0LyZw277etvvu3Jf0sclHW2qMADNKnkbf4ukJ2xf2c5/RMR/lRTT55jyeW277vltt72offzz+jebdN34mcMeEa9KunvW5wPoFl1vQBKEHUiCsANJEHYgCcIOJNHpENf3e2t8xB8bu36owyHn2bwOQR26oQ555lLSAAg7kAVhB5Ig7EAShB1IgrADSRB2IImFuZR0n5f27bsvu2S/9Gmep4seqkmXkubIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJzNV49pIxxKX9pn22XafN2ugLH22o+4Xx7AAIO5AFYQeSIOxAEoQdSIKwA0kQdiCJkimb37E77rqk1dX2pj4u0eaUzW22XWeR+9H7nGa7zhDPy6g9stveZ/uc7aMblm21fdD2y9XtllaqA9CYad7Gf0/SfVcte0jSoYi4XdKh6ncAA1Yb9oh4WtLFqxbvkrS/ur9f0gMN1wWgYbN+QXdLRJyRpOr25nEPtL3X9prttfMXLs/YHIBSrX8bHxErEbEUEUs33bCp7eYAjDFr2M/a3iZJ1e255koC0IZZw35A0p7q/h5JTzZTDoC21I5nt/24pHsl3SjprKSvSvpPST+S9BeSfiXpUxFx9Zd416i7bnybc17XafO68W22XWfIY8Ixm1nHs9eeVBMRu8esGn8VCgCDw+myQBKEHUiCsANJEHYgCcIOJNHpENdSQ+2ians4ZJtDXBdZm1NZD7m7dRyO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQxKD62UsuHVzab9nmENe6bbfZ57vI/extnp/Q53Drkte1vPPS2HUc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiUH1s/c5Be88T13c5zkCfZrn111ybsSk5x6PC2PXcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSRqp2xu0vu9NT7i8ZO/Drkve17bXmQlY877vtZ/W9cgWN55Umsv/HbklM21R3bb+2yfs310w7JHbP/a9uHq5/6ZqwPQiWnexn9P0n0jln8zInZUP081WxaAptWGPSKelnSxg1oAtKjkC7oHbR+p3uZvGfcg23ttr9lee1O/K2gOQIlZw/4dSR+StEPSGUlfH/fAiFiJiKWIWNqsd8/YHIBSM4U9Is5GxOWIeFvSdyUtN1sWgKbNFHbb2zb8+klJR8c9FsAw1I5nt/24pHsl3Wj7lKSvSrrX9g5JIemEpC9M09gdd13S6ursY9In6bPftM9rjNe13+e47C7an7Xtvq/138d+qQ17ROwesfixFmoB0CJOlwWSIOxAEoQdSIKwA0kQdiCJTi8lffzIda1dQrfOULuAFl2bf++S/drmv7XS9kva5lLSAAg7kAVhB5Ig7EAShB1IgrADSRB2IIlOLyW9dPd74her28euX9Qpm0v7bOe5n77N4bdDHl5bouR1FV1KGsBiIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDodz16HMeezyXop6TanRW77dbVVG+PZARB2IAvCDiRB2IEkCDuQBGEHkiDsQBKD6mcv6dvss598UcdVT2NR93vbr6uP/VZ7ZLe93fbPbB+z/ZLtL1XLt9o+aPvl6nZL++UCmNU0b+PfkvSViPhrSR+V9EXbd0p6SNKhiLhd0qHqdwADVRv2iDgTEc9X99+QdEzSrZJ2SdpfPWy/pAfaKhJAuXf0BZ3t2yR9WNIzkm6JiDPS+n8Ikm4e85y9ttdsr52/cLmsWgAzmzrstt8r6ceSvhwRr0/7vIhYiYiliFi66YZNs9QIoAFThd32Zq0H/QcR8ZNq8Vnb26r12ySda6dEAE2o7XqzbUmPSToWEd/YsOqApD2SHq1un6zb1qJO2dz3MNI+Ze12bPPy4G39vafpZ79H0mclvWj7SoUPaz3kP7L9eUm/kvSpVioE0IjasEfEzyWNvOi8pI81Ww6AtnC6LJAEYQeSIOxAEoQdSIKwA0kszJTNQzbk1zWvl0xu4vkl267TZtuTtv1MHNLrcZEpm4HMCDuQBGEHkiDsQBKEHUiCsANJEHYgiUH1s9cZar/pvPb/N6HPcwjabHtez42gnx0AYQeyIOxAEoQdSIKwA0kQdiAJwg4kMagpm+v02bdZcp3vRe6HX9TX1uZY+Wm23waO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQxDTzs2+X9H1JfybpbUkrEfEt249I+idJ56uHPhwRT03aVpvzsw+1D74JQ52XXhr2OQZ97rchnn8wzUk1b0n6SkQ8b/t9kp6zfbBa982I+Fp75QFoyjTzs5+RdKa6/4btY5JubbswAM16R5/Zbd8m6cOSnqkWPWj7iO19treMec5e22u2197U74qKBTC7qcNu+72SfizpyxHxuqTvSPqQpB1aP/J/fdTzImIlIpYiYmmz3t1AyQBmMVXYbW/WetB/EBE/kaSIOBsRlyPibUnflbTcXpkAStWG3bYlPSbpWER8Y8PybRse9klJR5svD0BTpvk2/h5Jn5X0ou0r/QkPS9pte4ekkHRC0hfqNnTHXZe0utrOUNEhdwGVGnLt1Na9Sa9reeelseum+Tb+55JGXYd6Yp86gGHhDDogCcIOJEHYgSQIO5AEYQeSIOxAEoO6lHSbQ1xL++GHOl103fb7Pv9gyPutzbZLlNR9PC6MXceRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeScER015h9XtL/bVh0o6TXOivgnRlqbUOtS6K2WTVZ219GxE2jVnQa9msat9ciYqm3AiYYam1DrUuitll1VRtv44EkCDuQRN9hX+m5/UmGWttQ65KobVad1NbrZ3YA3en7yA6gI4QdSKKXsNu+z/b/2n7F9kN91DCO7RO2X7R92PZaz7Xss33O9tENy7baPmj75ep25Bx7PdX2iO1fV/vusO37e6ptu+2f2T5m+yXbX6qW97rvJtTVyX7r/DO77U2Sjkv6R0mnJD0raXdE/HenhYxh+4SkpYjo/QQM238v6TeSvh8Rf1Mt+1dJFyPi0eo/yi0R8c8Dqe0RSb/pexrvaraibRunGZf0gKTPqcd9N6GuT6uD/dbHkX1Z0isR8WpE/F7SDyXt6qGOwYuIpyVdvGrxLkn7q/v7tf6PpXNjahuEiDgTEc9X99+QdGWa8V733YS6OtFH2G+VdHLD76c0rPneQ9JPbT9ne2/fxYxwS0Sckdb/8Ui6ued6rlY7jXeXrppmfDD7bpbpz0v1EfZRU0kNqf/vnoj4W0mfkPTF6u0qpjPVNN5dGTHN+CDMOv15qT7CfkrS9g2/f0DS6R7qGCkiTle35yQ9oeFNRX32ygy61e25nuv5gyFN4z1qmnENYN/1Of15H2F/VtLttj9o+12SPiPpQA91XMP29dUXJ7J9vaSPa3hTUR+QtKe6v0fSkz3W8keGMo33uGnG1fO+633684jo/EfS/Vr/Rv6Xkv6ljxrG1PVXkl6ofl7quzZJj2v9bd2bWn9H9HlJN0g6JOnl6nbrgGr7d0kvSjqi9WBt66m2v9P6R8Mjkg5XP/f3ve8m1NXJfuN0WSAJzqADkiDsQBKEHUiCsANJEHYgCcIOJEHYgST+H6+2D6KKwikkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare fake examples\n",
    "x_fake, y_fake = generate_fake_samples(generator, latent_dim, 1)\n",
    "generated_sample = x_fake[0].squeeze()\n",
    "plt.imshow(generated_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fecacb3e358>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare fake examples\n",
    "x_real, y_real = select_real_samples(x_train, 1)\n",
    "real_sample = x_real[0].squeeze()\n",
    "plt.imshow(real_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
