{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trippgordon/Desktop/Code/sonic/NoisyGAN\n",
      "\u001b[1m\u001b[36mData\u001b[m\u001b[m        README.md   \u001b[1m\u001b[36mcore\u001b[m\u001b[m        \u001b[1m\u001b[36mmodels\u001b[m\u001b[m      submit.sh\r\n",
      "\u001b[1m\u001b[36mNotebooks\u001b[m\u001b[m   __init__.py \u001b[1m\u001b[36mdepricated\u001b[m\u001b[m  \u001b[1m\u001b[36mnotes_ideas\u001b[m\u001b[m train.py\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:tf versionn: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%cd ..\n",
    "!ls\n",
    "from core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(ddsp.training.models.Model):\n",
    "    \"\"\"for now, just re-encode the fake sample. \n",
    "        in the future, just feed flz from fake right in\n",
    "        TODO: subclass ddsp Model\n",
    "    \"\"\"\n",
    "    def __init__(self, losses=['binary_crossentropy']):\n",
    "        super().__init__(name='discriminator', losses=self.buildLosses())\n",
    "        self.preprocessor = self.buildPreprocessor()\n",
    "        self.flzEncoder = self.buildFLZEncoder()\n",
    "        self.classifier = self.buildClassifier()\n",
    "        \n",
    "    def call(self, sample, label=1, training=True): # isFake param, only get flz if real?\n",
    "        \n",
    "        audio = sample['audio'] # must have shape (1,64000)\n",
    "        preprocessed = self.preprocessor(audio)\n",
    "        encoded = self.flzEncoder(preprocessed)\n",
    "        \n",
    "        # shape the shit into [1, 1000, 8, 1]\n",
    "        encoded_concat = tf.concat([encoded['f0_scaled'],\n",
    "                                    encoded['ld_scaled'],\n",
    "                                    encoded['z']], axis=2)\n",
    "        encoded_concat = tf.expand_dims(encoded_concat,axis=3)\n",
    "        \n",
    "        # classify if it's real or not\n",
    "        classification = self.classifier(encoded_concat)\n",
    "        \n",
    "        if training:\n",
    "            self.add_losses(label, classification)\n",
    "            \n",
    "        return classified\n",
    "        \n",
    "    def buildPreprocessor(self):\n",
    "        return ddsp.training.preprocessing.DefaultPreprocessor(time_steps=1000)\n",
    "\n",
    "    def buildFLZEncoder(self):\n",
    "        # TODO: try giving this an f0 encoder, like in ae_abs.gin\n",
    "        encoder = ddsp.training.encoders.MfccTimeDistributedRnnEncoder(z_dims=6,\n",
    "                                                                       z_time_steps=1000)\n",
    "        return encoder\n",
    "    \n",
    "    def buildClassifier(self):\n",
    "        # now encode even further down to a binary classification real or fake\n",
    "        discriminator = Sequential()\n",
    "        # downsample to 500x3\n",
    "        discriminator.add(Conv2D(16, (3,3), strides=(2, 2), padding='same', input_shape=(1000,6,1)))\n",
    "        discriminator.add(BatchNormalization())\n",
    "        discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        # downsample to 250 x 2\n",
    "        discriminator.add(Conv2D(16, (3,3), strides=(2, 2), padding='same', input_shape=(1000,6,1)))\n",
    "        discriminator.add(BatchNormalization())\n",
    "        discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        # downsample to 125 x 1\n",
    "        discriminator.add(Conv2D(16, (3,3), strides=(2, 2), padding='same', input_shape=(1000,6,1)))\n",
    "        discriminator.add(BatchNormalization())\n",
    "        discriminator.add(LeakyReLU(alpha=0.2))\n",
    "        # classify\n",
    "        discriminator.add(Flatten())\n",
    "        discriminator.add(Dense(1, activation='sigmoid'))\n",
    "        discriminator.summary()\n",
    "        \n",
    "        return discriminator\n",
    "    \n",
    "    def buildLosses(self):\n",
    "        # Loss functions\n",
    "        binary_crossentropy = tf.keras.losses.binary_crossentropy()\n",
    "        losses=[binary_crossentropy]\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealSample(sampleNum):\n",
    "    # get a dataset\n",
    "    output_tfrecord_path = './Data/piano/piano30s.tfrecord'\n",
    "    dataset = DDSP_DATASET(output_tfrecord_path)\n",
    "    # get a sample\n",
    "    real_sample = dataset.getSample(sampleNum=sampleNum)\n",
    "    real_sample['audio'] = tf.expand_dims(real_sample['audio'],axis=[0]) \n",
    "    return real_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "describeSample() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4b6548d57bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreal_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetRealSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdescribeSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: describeSample() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "real_sample = getRealSample(0)\n",
    "describeSample(real_sample,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "binary_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-921c538f300d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-1d66a3663940>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, losses)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'discriminator'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildLosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflzEncoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildFLZEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-1d66a3663940>\u001b[0m in \u001b[0;36mbuildLosses\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuildLosses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Loss functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mbinary_crossentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: binary_crossentropy() missing 2 required positional arguments: 'y_true' and 'y_pred'"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "discriminator(real_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
