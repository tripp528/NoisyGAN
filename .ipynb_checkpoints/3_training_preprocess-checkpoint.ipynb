{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpJd3dlOCStH"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/tutorials/3_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hMqWDc_m6rUC"
   },
   "source": [
    "\n",
    "##### Copyright 2020 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNhgka4UKNjf"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGES/NOTES\n",
    "\n",
    "<ul>\n",
    "    <li>Changed AUDIO_FILEPATTERN from AUDIO_DIR+\"*\" to AUDIO_DIR+\"*.wav\"</li>\n",
    "    <ul>\n",
    "        <li>Reason: ffmpeg was trying to parse a file with extension .DG_something</li>\n",
    "    </ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "!pip install -qU ddsp[data_preparation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFIqwYGbZ-df"
   },
   "source": [
    "# DDSP Training\n",
    "\n",
    "This notebook demonstrates the libraries in [https://github.com/magenta/ddsp/tree/master/ddsp/training](https://github.com/magenta/ddsp/tree/master/ddsp/training). It is a simple example, overfitting a single audio sample, for educational purposes. \n",
    "\n",
    "_For a full training pipeline please use [ddsp/training/ddsp_run.py](https://github.com/magenta/ddsp/blob/master/ddsp/training/README.md#train-1) as in the [train_autoencoder.ipynb](https://github.com/magenta/ddsp/blob/master/ddsp/colab/demos/train_autoencoder.ipynb)_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "S_jXCnwZ2QYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/trippgordon/miniconda3/envs/cs254/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#@title Install and import dependencies\n",
    "\n",
    "!pip install -qU ddsp\n",
    "\n",
    "# Ignore a bunch of deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "\n",
    "#from ddsp.colab.colab_utils import play, specplot, DEFAULT_SAMPLE_RATE\n",
    "\n",
    "import gin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "sample_rate = 16000 #\n",
    "DEFAULT_SAMPLE_RATE = 16000\n",
    "\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories might take some messing around with\n",
    "\n",
    "AUDIO_DIR = 'data/audio'\n",
    "AUDIO_FILEPATTERN = AUDIO_DIR + '/*.wav'\n",
    "!mkdir -p $AUDIO_DIR\n",
    "\n",
    "TRAIN_TFRECORD = 'data/train3.tfrecord'\n",
    "TRAIN_TFRECORD_FILEPATTERN = TRAIN_TFRECORD + '*'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/trippgordon/miniconda3/envs/cs254/bin/ddsp_prepare_tfrecord\", line 6, in <module>\r\n",
      "    from ddsp.training.data_preparation.prepare_tfrecord import console_entry_point\r\n",
      "  File \"/Users/trippgordon/miniconda3/envs/cs254/lib/python3.7/site-packages/ddsp/training/data_preparation/__init__.py\", line 18, in <module>\r\n",
      "    from ddsp.training.data_preparation import prepare_tfrecord_lib\r\n",
      "  File \"/Users/trippgordon/miniconda3/envs/cs254/lib/python3.7/site-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 19, in <module>\r\n",
      "    import apache_beam as beam\r\n",
      "ModuleNotFoundError: No module named 'apache_beam'\r\n"
     ]
    }
   ],
   "source": [
    "TRAIN_TFRECORD = 'data/train3.tfrecord'\n",
    "TRAIN_TFRECORD_FILEPATTERN = TRAIN_TFRECORD + '*'\n",
    "\n",
    "\n",
    "!ddsp_prepare_tfrecord \\\n",
    "  --input_audio_filepatterns=$AUDIO_FILEPATTERN \\\n",
    "  --output_tfrecord_path=$TRAIN_TFRECORD \\\n",
    "  --num_shards=10 \\\n",
    "  --alsologtostderr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code should work up to here\n",
    "## Getting errors from here on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:189: The name tf.estimator.tpu.RunConfig is deprecated. Please use tf.compat.v1.estimator.tpu.RunConfig instead.\n",
      "\n",
      "W0126 15:58:30.118949 140735582221184 module_wrapper.py:139] From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:189: The name tf.estimator.tpu.RunConfig is deprecated. Please use tf.compat.v1.estimator.tpu.RunConfig instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:191: The name tf.estimator.tpu.TPUConfig is deprecated. Please use tf.compat.v1.estimator.tpu.TPUConfig instead.\n",
      "\n",
      "W0126 15:58:30.119210 140735582221184 module_wrapper.py:139] From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:191: The name tf.estimator.tpu.TPUConfig is deprecated. Please use tf.compat.v1.estimator.tpu.TPUConfig instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:199: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n",
      "W0126 15:58:30.119525 140735582221184 module_wrapper.py:139] From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:199: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/content/models/ddsp-solo-instrument', '_tf_random_seed': None, '_save_summary_steps': 300, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 1, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c4c42a510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=300, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "I0126 15:58:30.120301 140735582221184 estimator.py:212] Using config: {'_model_dir': '/content/models/ddsp-solo-instrument', '_tf_random_seed': None, '_save_summary_steps': 300, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 100, '_keep_checkpoint_every_n_hours': 1, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c4c42a510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=300, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu False\n",
      "I0126 15:58:30.120702 140735582221184 tpu_context.py:220] _TPUContext: eval_on_tpu False\n",
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0126 15:58:30.125300 140735582221184 deprecation.py:506] From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0126 15:58:30.125690 140735582221184 deprecation.py:323] From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "I0126 15:58:30.698426 140735582221184 utils.py:141] NumExpr defaulting to 4 threads.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0126 15:58:31.664937 140735582221184 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "I0126 15:58:31.665129 140735582221184 tpu_estimator.py:3124] Running train on CPU\n",
      "I0126 15:58:32.590077 140735582221184 processors.py:138] Connecting node (additive):\n",
      "I0126 15:58:32.590250 140735582221184 processors.py:140] Input 0: amps\n",
      "I0126 15:58:32.590330 140735582221184 processors.py:140] Input 1: harmonic_distribution\n",
      "I0126 15:58:32.590381 140735582221184 processors.py:140] Input 2: f0_hz\n",
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/core.py:296: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0126 15:58:32.603632 140735582221184 deprecation.py:323] From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/core.py:296: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0126 15:58:32.708109 140735582221184 processors.py:138] Connecting node (filtered_noise):\n",
      "I0126 15:58:32.708488 140735582221184 processors.py:140] Input 0: noise_magnitudes\n",
      "I0126 15:58:32.878561 140735582221184 processors.py:138] Connecting node (add):\n",
      "I0126 15:58:32.878741 140735582221184 processors.py:140] Input 0: filtered_noise/signal\n",
      "I0126 15:58:32.878810 140735582221184 processors.py:140] Input 1: additive/signal\n",
      "I0126 15:58:32.879667 140735582221184 processors.py:138] Connecting node (reverb):\n",
      "I0126 15:58:32.879776 140735582221184 processors.py:140] Input 0: add/signal\n",
      "I0126 15:58:33.036556 140735582221184 processors.py:157] ProcessorGroup output node (reverb)\n",
      "I0126 15:58:34.072126 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc/dense/kernel:0 (shape=(1, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072283 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072360 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc/layer_normalization/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072412 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc/layer_normalization/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0126 15:58:34.072484 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_1/dense/kernel:0 (shape=(512, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072545 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_1/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072593 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_1/layer_normalization_1/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072653 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_1/layer_normalization_1/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072721 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_2/dense/kernel:0 (shape=(512, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.072798 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_2/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.073353 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_2/layer_normalization_2/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.073504 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack/fc_2/layer_normalization_2/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.073601 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc/dense/kernel:0 (shape=(1, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.073747 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.073853 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc/layer_normalization_3/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074087 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc/layer_normalization_3/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074240 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_1/dense/kernel:0 (shape=(512, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074378 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_1/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074476 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_1/layer_normalization_4/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074599 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_1/layer_normalization_4/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074646 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_2/dense/kernel:0 (shape=(512, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074695 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_2/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074743 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_2/layer_normalization_5/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074790 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_1/fc_2/layer_normalization_5/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074836 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/gru/kernel:0 (shape=(1024, 1536), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074886 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/gru/recurrent_kernel:0 (shape=(512, 1536), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074937 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/gru/bias:0 (shape=(1536,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.074983 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc/dense/kernel:0 (shape=(1536, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075031 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075078 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc/layer_normalization_6/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075125 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc/layer_normalization_6/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075184 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_1/dense/kernel:0 (shape=(512, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075257 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_1/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075311 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_1/layer_normalization_7/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075377 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_1/layer_normalization_7/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075436 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_2/dense/kernel:0 (shape=(512, 512), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075488 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_2/dense/bias:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075544 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_2/layer_normalization_8/gamma:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075601 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/fc_stack_2/fc_2/layer_normalization_8/beta:0 (shape=(512,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075649 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/dense/kernel:0 (shape=(512, 126), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075717 140735582221184 models.py:230] adding trainable variable rnn_fc_decoder/dense/bias:0 (shape=(126,), dtype=<dtype: 'float32'>).\n",
      "I0126 15:58:34.075773 140735582221184 models.py:230] adding trainable variable ir:0 (shape=(48000,), dtype=<dtype: 'float32'>).\n",
      "WARNING:tensorflow:From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:126: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.\n",
      "\n",
      "W0126 15:58:36.679579 140735582221184 module_wrapper.py:139] From /Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py:126: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0126 15:58:36.712813 140735582221184 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0126 15:58:36.714761 140735582221184 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "ERROR:tensorflow:Error recorded from training_loop: /content/models/ddsp-solo-instrument; Permission denied\n",
      "E0126 15:58:36.715151 140735582221184 error_handling.py:75] Error recorded from training_loop: /content/models/ddsp-solo-instrument; Permission denied\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "I0126 15:58:36.715231 140735582221184 error_handling.py:101] training_loop marked as finished\n",
      "WARNING:tensorflow:Reraising captured error\n",
      "W0126 15:58:36.715301 140735582221184 error_handling.py:135] Reraising captured error\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/bin/ddsp_run\", line 8, in <module>\n",
      "    sys.exit(console_entry_point())\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/ddsp_run.py\", line 187, in console_entry_point\n",
      "    app.run(main)\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/ddsp_run.py\", line 181, in main\n",
      "    run()\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/ddsp_run.py\", line 156, in run\n",
      "    use_tpu=FLAGS.use_tpu)\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/gin/config.py\", line 1078, in gin_wrapper\n",
      "    utils.augment_exception_message_and_reraise(e, err_str)\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/gin/utils.py\", line 49, in augment_exception_message_and_reraise\n",
      "    six.raise_from(proxy.with_traceback(exception.__traceback__), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/gin/config.py\", line 1055, in gin_wrapper\n",
      "    return fn(*new_args, **new_kwargs)\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/ddsp/training/train_util.py\", line 230, in train\n",
      "    estimator.train(input_fn=input_fn, max_steps=num_steps)\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3035, in train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    rendezvous.raise_errors()\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\", line 136, in raise_errors\r\n",
      "    six.reraise(typ, value, traceback)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/six.py\", line 693, in reraise\r\n",
      "    raise value\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\r\n",
      "    saving_listeners=saving_listeners)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\r\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\r\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\r\n",
      "    saving_listeners)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1490, in _train_with_estimator_spec\r\n",
      "    log_step_count_steps=log_step_count_steps) as mon_sess:\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 584, in MonitoredTrainingSession\r\n",
      "    stop_grace_period_secs=stop_grace_period_secs)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1014, in __init__\r\n",
      "    stop_grace_period_secs=stop_grace_period_secs)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 713, in __init__\r\n",
      "    h.begin()\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 557, in begin\r\n",
      "    self._summary_writer = SummaryWriterCache.get(self._checkpoint_dir)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/summary/writer/writer_cache.py\", line 63, in get\r\n",
      "    logdir, graph=ops.get_default_graph())\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/summary/writer/writer.py\", line 367, in __init__\r\n",
      "    filename_suffix)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/summary/writer/event_file_writer.py\", line 67, in __init__\r\n",
      "    gfile.MakeDirs(self._logdir)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 438, in recursive_create_dir\r\n",
      "    recursive_create_dir_v2(dirname)\r\n",
      "  File \"/Users/tomhanlon58/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 453, in recursive_create_dir_v2\r\n",
      "    pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(path))\r\n",
      "tensorflow.python.framework.errors_impl.PermissionDeniedError: /content/models/ddsp-solo-instrument; Permission denied\r\n",
      "  In call to configurable 'train' (<function train at 0x1c4c361200>)\r\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = '/content/models/ddsp-solo-instrument'\n",
    "\n",
    "!ddsp_run \\\n",
    "  --mode=train \\\n",
    "  --alsologtostderr \\\n",
    "  --model_dir=$MODEL_DIR \\\n",
    "  --num_train_steps=1 \\\n",
    "  --gin_file=models/solo_instrument.gin \\\n",
    "  --gin_file=datasets/tfrecord.gin \\\n",
    "  --gin_param=\"TFRecordProvider.file_pattern='data/train3.tfrecord*'\" \\\n",
    "  --gin_param=batch_size=16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotControls(amplitudes, harmonic_distribution, f0_hz):\n",
    "    '''Plots the controls (inputs) to a ddsp processor'''\n",
    "    \n",
    "    time = np.linspace(0, n_samples / sample_rate, n_frames)\n",
    "\n",
    "    plt.figure(figsize=(18, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(time, amplitudes[0, :, 0])\n",
    "    plt.xticks([0, 1, 2, 3, 4])\n",
    "    plt.title('Amplitude')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot(time, harmonic_distribution[0, :, :])\n",
    "    plt.xticks([0, 1, 2, 3, 4])\n",
    "    plt.title('Harmonic Distribution')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(time, f0_hz[0, :, 0])\n",
    "    plt.xticks([0, 1, 2, 3, 4])\n",
    "    _ = plt.title('Fundamental Frequency')\n",
    "    \n",
    "def specPlot(audio, sr=DEFAULT_SAMPLE_RATE):\n",
    "    '''takes a tensor as input (from ddsp)'''\n",
    "    # short term forier transform\n",
    "    X = librosa.stft(audio.squeeze())\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.show()\n",
    "    \n",
    "def wavePlot(audio):\n",
    "    '''takes a tensor as input (from ddsp)'''\n",
    "    # plot waveform\n",
    "    librosa.display.waveplot(audio.numpy().squeeze())\n",
    "    plt.show()\n",
    "    \n",
    "def play(audio, sr=DEFAULT_SAMPLE_RATE):\n",
    "    return ipd.Audio(audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khYj8yiMDxGL"
   },
   "source": [
    "# Get a Batch of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzzaWKxVkYms"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Using public TFDS GCS bucket to load NSynth. If not running on GCP, this will be very slow, and it is recommended you prepare the dataset locally with TFDS and set the data_dir appropriately.\n"
     ]
    }
   ],
   "source": [
    "# Get a single example from NSynth.\n",
    "# Takes a few seconds to load from GCS.\n",
    "tf.reset_default_graph()\n",
    "data_provider = ddsp.training.data.NSynthTfds(split='test')\n",
    "batch = data_provider.get_batch(batch_size=1, shuffle=False)\n",
    "batch = next(tfds.as_numpy(batch))\n",
    "audio = batch['audio']\n",
    "n_samples = audio.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 64000)\n"
     ]
    }
   ],
   "source": [
    "print(type(audio))\n",
    "print(audio.shape)\n",
    "\n",
    "#specPlot(audio)\n",
    "#play(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bo337pQdDiar"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWZQXFLehCU0"
   },
   "source": [
    "### Model in python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCqXRY1KeX8S"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "preprocessing = ddsp.training.preprocessing\n",
    "encoders = ddsp.training.encoders\n",
    "decoders = ddsp.training.decoders\n",
    "models = ddsp.training.models\n",
    "TIME_STEPS = 1000\n",
    "\n",
    "# Create Neural Networks.\n",
    "preprocessor = preprocessing.DefaultPreprocessor(time_steps=TIME_STEPS)\n",
    "\n",
    "decoder = decoders.RnnFcDecoder(rnn_channels = 256,\n",
    "                                rnn_type = 'gru',\n",
    "                                ch = 256,\n",
    "                                layers_per_stack = 1,\n",
    "                                output_splits = (('amps', 1),\n",
    "                                                 ('harmonic_distribution', 20),\n",
    "                                                 ('noise_magnitudes', 20)))\n",
    "\n",
    "# Create Processors.\n",
    "additive = ddsp.synths.Additive(n_samples=n_samples, \n",
    "                                sample_rate=sample_rate,\n",
    "                                name='additive')\n",
    "noise = ddsp.synths.FilteredNoise(window_size=0,\n",
    "                                  initial_bias=-10.0,\n",
    "                                  name='noise')\n",
    "add = ddsp.processors.Add(name='add')\n",
    "\n",
    "# Create ProcessorGroup.\n",
    "dag = [(additive, ['amps', 'harmonic_distribution', 'f0_hz']),\n",
    "       (noise, ['noise_magnitudes']),\n",
    "       (add, ['noise/signal', 'additive/signal'])]\n",
    "\n",
    "processor_group = ddsp.processors.ProcessorGroup(dag=dag,\n",
    "                                                 name='processor_group')\n",
    "\n",
    "\n",
    "# Loss_functions\n",
    "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
    "                                         mag_weight=1.0,\n",
    "                                         logmag_weight=1.0)\n",
    "\n",
    "# Put it together in a model.\n",
    "model = models.Autoencoder(preprocessor=preprocessor,\n",
    "                           encoder=None,\n",
    "                           decoder=decoder,\n",
    "                           processor_group=processor_group,\n",
    "                           losses=[spectral_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAZgDMV9hGyp"
   },
   "source": [
    "#### Or model in gin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JPmTwQshVya"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "gin_string = \"\"\"\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "\n",
    "# Preprocessor\n",
    "models.Autoencoder.preprocessor = @preprocessing.DefaultPreprocessor()\n",
    "preprocessing.DefaultPreprocessor.time_steps = 1000\n",
    "\n",
    "\n",
    "# Encoder\n",
    "models.Autoencoder.encoder = None\n",
    "\n",
    "# Decoder\n",
    "models.Autoencoder.decoder = @decoders.RnnFcDecoder()\n",
    "decoders.RnnFcDecoder.rnn_channels = 256\n",
    "decoders.RnnFcDecoder.rnn_type = 'gru'\n",
    "decoders.RnnFcDecoder.ch = 256\n",
    "decoders.RnnFcDecoder.layers_per_stack = 1\n",
    "decoders.RnnFcDecoder.output_splits = (('amps', 1),\n",
    "                                       ('harmonic_distribution', 20),\n",
    "                                       ('noise_magnitudes', 20))\n",
    "\n",
    "# ProcessorGroup\n",
    "models.Autoencoder.processor_group = @processors.ProcessorGroup()\n",
    "\n",
    "processors.ProcessorGroup.dag = [\n",
    "  (@additive/synths.Additive(),\n",
    "    ['amps', 'harmonic_distribution', 'f0_hz']),\n",
    "  (@noise/synths.FilteredNoise(),\n",
    "    ['noise_magnitudes']),\n",
    "  (@add/processors.Add(),\n",
    "    ['noise/signal', 'additive/signal']),\n",
    "]\n",
    "\n",
    "# Additive Synthesizer\n",
    "additive/synths.Additive.name = 'additive'\n",
    "additive/synths.Additive.n_samples = 64000\n",
    "additive/synths.Additive.scale_fn = @core.exp_sigmoid\n",
    "\n",
    "# Filtered Noise Synthesizer\n",
    "noise/synths.FilteredNoise.name = 'noise'\n",
    "noise/synths.FilteredNoise.n_samples = 64000\n",
    "noise/synths.FilteredNoise.initial_bias = -10.0\n",
    "\n",
    "# Add\n",
    "add/processors.Add.name = 'add'\n",
    "\n",
    "models.Autoencoder.losses = [\n",
    "    @losses.SpectralLoss(),\n",
    "]\n",
    "losses.SpectralLoss.loss_type = 'L1'\n",
    "losses.SpectralLoss.mag_weight = 1.0\n",
    "losses.SpectralLoss.logmag_weight = 1.0\n",
    "\"\"\"\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_string)\n",
    "\n",
    "# Autoencoder arguments are filled by gin.\n",
    "model = ddsp.training.models.Autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSsvL1geY0_S"
   },
   "source": [
    "## Get training op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.NSynthTfds(split='test')\n",
    "batch = data_provider.get_batch(batch_size=1, shuffle=False)\n",
    "batch = next(tfds.as_numpy(batch))\n",
    "audio = batch['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1lQW604_QWm1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1e5a068f3ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get model predictions for the batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "use_tpu = False  # Set: Runtime -> Set Runtime Type -> (TPU or GPU)\n",
    "\n",
    "# Get model predictions for the batch.\n",
    "start_time = time.time()\n",
    "outputs = model(batch)\n",
    "loss = outputs['total_loss']\n",
    "\n",
    "print(type(batch))\n",
    "print(batch.keys())\n",
    "print(type(data_provider))\n",
    "print(type(outputs))\n",
    "print(outputs.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_op = ddsp.training.train_util.get_train_op(loss, #learning_rate=learning_rate,\n",
    "                                                 use_tpu=use_tpu)\n",
    "'''                                            \n",
    "                                            \n",
    "print('Setting up the graph took %.1f seconds' % (time.time() - start_time))\n",
    "\n",
    "# Setup the session.\n",
    "if use_tpu:\n",
    "  import os\n",
    "  assert \"COLAB_TPU_ADDR\" in os.environ, \"ERROR: Not connected to a TPU runtime; please set the runtime type to 'TPU'.\"\n",
    "  TPU_ADDRESS = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
    "  sess = tf.Session(TPU_ADDRESS)\n",
    "else:\n",
    "  # Set: Runtime -> Set Runtime Type -> GPU\n",
    "  sess = tf.Session()\n",
    "\n",
    "start_time = time.time()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "print('Initializing model took %.1f seconds' % (time.time() - start_time))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFEqt6e1DsqG"
   },
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWdoRIONDxri"
   },
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "  _, loss_ = sess.run([train_op, loss])\n",
    "  print('i: {}\\tLoss: {}'.format(i, loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cj220vSF8_Y"
   },
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDU_FysURm_Z"
   },
   "outputs": [],
   "source": [
    "# Run a batch of predictions.\n",
    "start_time = time.time()\n",
    "predictions = sess.run(outputs)\n",
    "print('Prediction took %.1f seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVhoLzV-ZYav"
   },
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "get = lambda key: ddsp.core.nested_lookup(key, predictions)[batch_idx]\n",
    "\n",
    "audio = get('audio')\n",
    "audio_gen = get('audio_gen')\n",
    "amps = get('additive/controls/amplitudes')\n",
    "harmonic_distribution = get('additive/controls/harmonic_distribution')\n",
    "f0_hz = get('f0_hz')\n",
    "loudness = get('loudness_db')\n",
    "\n",
    "print('Original Audio')\n",
    "play(audio)\n",
    "print('Resynthesized Audio')\n",
    "play(audio_gen)\n",
    "\n",
    "specplot(audio, sess=sess)\n",
    "plt.title('Audio')\n",
    "specplot(audio_gen, sess=sess)\n",
    "plt.title('Audio Synth')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "ax[0].semilogy(amps)\n",
    "ax[0].set_xlabel('Amps')\n",
    "ax[0].set_ylim(1e-5, 2)\n",
    "ax[1].plot(loudness)\n",
    "ax[1].set_xlabel('loudness')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "ax[0].plot(harmonic_distribution)\n",
    "ax[0].set_title('Harmonic Distribution')\n",
    "ax[1].plot(f0_hz)\n",
    "_ = ax[1].set_title('F0_Hz')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "hMqWDc_m6rUC"
   ],
   "last_runtime": {},
   "name": "3_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
